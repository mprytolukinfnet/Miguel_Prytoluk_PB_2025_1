# Projeto de Bloco: Arquitetura Lambda com Apache Airflow, MinIO, e Streaming com Kafka

Este projeto implementa uma Arquitetura Lambda completa para processamento de dados, combinando uma camada de batch (Apache Airflow + MinIO) com uma camada de velocidade (Apache Kafka + Redis). O pipeline Ã© totalmente automatizado, nÃ£o requerendo intervenÃ§Ã£o manual para sua execuÃ§Ã£o.

## ğŸ—ï¸ Arquitetura do Sistema

### Camada Batch (Serving Layer)
O pipeline batch Ã© orquestrado pelo Airflow e executa automaticamente apÃ³s a inicializaÃ§Ã£o do sistema:

1. **CriaÃ§Ã£o de Buckets**: Configura automaticamente os buckets necessÃ¡rios no MinIO.
2. **ExtraÃ§Ã£o e Carga (Bronze)**: Baixa os dados de tÃ¡xi de NY e armazena no bucket `bronze`.
3. **TransformaÃ§Ã£o (Silver)**: Processa os dados brutos e salva no bucket `silver`.
4. **AgregaÃ§Ã£o (Gold)**: Calcula mÃ©tricas de negÃ³cio e disponibiliza no bucket `gold`.

### Camada Speed (Real-time Layer)
A camada de velocidade processa eventos em tempo real usando Kafka e Redis:

1. **Producer**: Monitora novos dados no MinIO e envia eventos para o Kafka.
2. **Consumer**: Processa eventos em tempo real e atualiza mÃ©tricas no Redis.
3. **Armazenamento**: Utiliza Redis para manter as mÃ©tricas em tempo real atualizadas.

## ğŸ“‹ PrÃ©-requisitos

* Docker
* Docker Compose

## âš™ï¸ ConfiguraÃ§Ã£o

1. **Clone o RepositÃ³rio**:
```bash
git clone https://github.com/mprytolukinfnet/Miguel_Prytoluk_PB_2025_1.git
cd tp5_app
```

2. **Configure o Ambiente**:
Crie um arquivo `.env` na raiz do projeto:

```env
# Airflow
AIRFLOW_UID=50000

# MinIO Configuration
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin

# Bucket Names
BRONZE_BUCKET=bronze-bucket
SILVER_BUCKET=silver-bucket
GOLD_BUCKET=gold-bucket
```

## ğŸš€ Como Executar

Execute o sistema completo com um Ãºnico comando:

```bash
docker compose up
```

O sistema iniciarÃ¡ automaticamente:
- O Airflow DAG serÃ¡ ativado e executado automaticamente
- O producer Kafka comeÃ§arÃ¡ a monitorar novos dados
- O consumer Kafka processarÃ¡ eventos em tempo real

## ğŸŒ Acessando os ServiÃ§os

- **Airflow**: http://localhost:8080 (usuÃ¡rio: `airflow`, senha: `airflow`)
- **MinIO Console**: http://localhost:9091 (usuÃ¡rio: `minioadmin`, senha: `minioadmin`)
- **Kafka**: Porta 29092 (interno), 9092 (externo)
- **Redis**: Porta 6379

## ğŸ“‚ Estrutura do Projeto

```
/Miguel_Prytoluk_PB_2025_1
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ batch_pipeline_taxi_nyc.py
â”œâ”€â”€ streaming/
â”‚   â”œâ”€â”€ producer.py
â”‚   â”œâ”€â”€ speed_consumer.py
â”‚   â”œâ”€â”€ create_topic.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ minio_setup_files/
â”‚   â””â”€â”€ setup.sh
â”œâ”€â”€ .env
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ streaming.Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ trigger_dag.sh
```

## ğŸ”„ Fluxo de ExecuÃ§Ã£o

1. **InicializaÃ§Ã£o**:
   - Os serviÃ§os Docker sÃ£o iniciados
   - MinIO Ã© configurado com os buckets necessÃ¡rios
   - O tÃ³pico Kafka Ã© criado
   - O Airflow Ã© inicializado e o DAG Ã© ativado automaticamente

2. **Pipeline de Batch**:
   - O DAG Ã© executado automaticamente apÃ³s a inicializaÃ§Ã£o
   - Os dados sÃ£o processados atravÃ©s das camadas Bronze â†’ Silver â†’ Gold

3. **Pipeline de Speed**:
   - O producer monitora continuamente novos dados
   - Eventos sÃ£o enviados para o Kafka
   - O consumer processa os eventos em tempo real
   - As mÃ©tricas sÃ£o atualizadas no Redis

## ğŸ“Š Monitoramento

- Use a UI do Airflow para monitorar o pipeline de batch
- Verifique os dados processados no Console do MinIO
- Monitore as mÃ©tricas em tempo real no Redis